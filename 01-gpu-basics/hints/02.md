# Hints for Exercise 02 — Vector Add

## Hint 1: The kernel
Same indexing as exercise 01, but now you READ from two arrays and WRITE to one:
```cuda
int idx = blockIdx.x * blockDim.x + threadIdx.x;
if (idx < n) {
    C[idx] = A[idx] + B[idx];
}
```

## Hint 2: Multiple allocations
You need three `cudaMalloc` calls — one for each array (d_A, d_B, d_C).

## Hint 3: Transfer pattern
```
Host → Device:  cudaMemcpy(d_A, h_A, bytes, cudaMemcpyHostToDevice);
Device → Host:  cudaMemcpy(h_C, d_C, bytes, cudaMemcpyDeviceToHost);
```

## Hint 4: Non-power-of-2 sizes
N = 1000003 is not divisible by 256. Your ceiling division handles this:
```
blocks = (N + THREADS - 1) / THREADS;  // = 3907
```
The last block will have some idle threads — that's fine, the bounds check in the kernel handles it.
