# Hints for Exercise 01 — Hello GPU

## Hint 1: The kernel body
Each thread should compute ONE global index and write to that position:
```cuda
int idx = blockIdx.x * blockDim.x + threadIdx.x;
```
Don't forget: what if `idx >= n`?

## Hint 2: Grid size calculation
You need enough blocks to cover all N elements:
```
blocks = (N + THREADS - 1) / THREADS;
```
This is "ceiling division" — the most common pattern in CUDA.

## Hint 3: cudaMalloc
```cuda
CUDA_CHECK(cudaMalloc(&d_out, N * sizeof(int)));
```
Note the `&` — cudaMalloc takes a pointer-to-pointer.

## Hint 4: cudaMemcpy direction
```cuda
cudaMemcpy(h_out, d_out, N * sizeof(int), cudaMemcpyDeviceToHost);
```
The direction enum: `cudaMemcpyDeviceToHost`, `cudaMemcpyHostToDevice`.
