# Hints — Vectorized Loads

## float4 load pattern
```cuda
// Loading a row of A into shared memory, 4 elements at a time
int loadRow = threadIdx.x / (BK / 4);
int loadCol = (threadIdx.x % (BK / 4)) * 4;

int globalRow = blockIdx.y * BM + loadRow;
int globalCol = bk_offset + loadCol;

float4 tmp = reinterpret_cast<const float4*>(&A[globalRow * K + globalCol])[0];
As[loadRow][loadCol + 0] = tmp.x;
As[loadRow][loadCol + 1] = tmp.y;
As[loadRow][loadCol + 2] = tmp.z;
As[loadRow][loadCol + 3] = tmp.w;
```

## Multiple loads per thread
If BM×BK = 128×8 = 1024 elements and you have 256 threads:
- Each thread loads 1024/256 = 4 elements = 1 float4
- If BM×BK > numThreads×4, use a stride loop
