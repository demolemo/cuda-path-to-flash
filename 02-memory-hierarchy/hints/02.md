# Hints — Matrix Transpose

## Naive
```cuda
if (row < height && col < width)
    B[col * height + row] = A[row * width + col];
```

## Shared memory (the tricky part)
The key: block (bx, by) reads from A but writes to a TRANSPOSED position in B.

```cuda
int x_in = blockIdx.x * TILE + threadIdx.x;  // col in A
int y_in = blockIdx.y * TILE + threadIdx.y;  // row in A

// Load from A (coalesced — consecutive threads read consecutive cols)
if (y_in < height && x_in < width)
    tile[threadIdx.y][threadIdx.x] = A[y_in * width + x_in];
__syncthreads();

// Write to B — swap block indices
int x_out = blockIdx.y * TILE + threadIdx.x;  // was y, now x
int y_out = blockIdx.x * TILE + threadIdx.y;  // was x, now y

// Read from tile with swapped indices (this does the transpose)
if (y_out < width && x_out < height)
    B[y_out * height + x_out] = tile[threadIdx.x][threadIdx.y];
```

## Why padding fixes bank conflicts
`tile[TILE][TILE]`: thread 0 reads `tile[0][0]` (bank 0), thread 1 reads `tile[1][0]` (bank 0 again!) — 32-way conflict!
`tile[TILE][TILE+1]`: thread 0 reads `tile[0][0]` (bank 0), thread 1 reads `tile[1][0]` (bank 1) — no conflict!
